# Reference Model Fine-tuning Local Test
# M3 Mac 경량 테스트용

project:
  name: weighted-mtp
  version: "2.0.0"

experiment:
  name: ref-tuning-local
  description: "Local test for reference model fine-tuning"
  stage: ref-tuning
  tags:
    - ref-tuning
    - local
    - huggingface

# 모델 설정 (HuggingFace 형식)
models:
  policy:
    name: micro-ref-hf
    path: storage/models/micro-ref-hf
    dtype: float32

dataset:
  name: codecontests
  train: storage/datasets/codecontests/processed/train.jsonl
  validation: storage/datasets/codecontests/processed/valid.jsonl
  max_length: 512

data_sampling:
  seed: 42
  val_n_samples: 10
  use_pairwise: false

  n_samples: 20
  max_pairs_per_problem: 25

  difficulty_bins:
    diff_7: [7, 7]
    else: [8, 25]
  difficulty_weights:
    diff_7: 0.35
    else: 0.65

training:
  n_epochs: 0.1
  batch_size: 2
  gradient_accumulation_steps: 2
  learning_rate: 2.0e-5
  max_grad_norm: 1.0
  log_interval: 5

  # LoRA 설정: ref-tuning은 HuggingFace 모델 사용으로 현재 미지원
  use_lora: false

  lr_scheduler:
    type: cosine
    warmup_ratio: 0.05
    min_lr_ratio: 0.0

checkpoint:
  save_dir: storage/checkpoints/ref-tuning/${experiment.name}
  save_checkpoint_every: 0.1
  save_best: true
  save_final: true
  save_total_limit: 2
  s3_upload: false

runtime:
  device: mps
  seed: 42
  mixed_precision: false

distributed:
  fsdp:
    sharding_strategy: NO_SHARD
    mixed_precision: false
    cpu_offload: false
    activation_checkpointing: false

storage:
  root: storage
  models_dir: storage/models
  datasets_dir: storage/datasets
  checkpoints_dir: storage/checkpoints

mlflow:
  tracking_uri: "sqlite:///mlflow.db"
  experiment: "weighted_mtp"
  s3_artifacts: ""

logging:
  level: INFO
  format: "%(asctime)s [%(levelname)s] [%(name)s] %(message)s"
